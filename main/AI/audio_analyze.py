# -*- coding: utf-8 -*-
"""Audio analyze

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gqoztuueyUSigBPX8W0NoSEOgRkibjUL

# CNN BASED Music Emotion Classification
"""

from google.colab import drive
drive.mount('/content/drive')
    
data_path = '/content/drive/MyDrive/sample' 
test_data_path = '/content/drive/MyDrive/test'

# Module Import 
import librosa
import numpy as np
import matplotlib.pyplot as plt
import torch
import os
import pandas as pd
import csv
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import soundfile as sf
import random
import re


from glob import glob
from PIL import Image
from torch.utils.data import Dataset
from skimage import io
from torchvision.io import read_image

# Read csv file
csv_path ='/content/drive/MyDrive/sample/Labels.csv'
data_frame = pd.read_csv(csv_path)


#data_frame.iloc[0]
#
#Name      Labels
#sample1     4
#sample2     4

print(data_frame)

# For wave image , wav files are transformed by stft 
# wav transform 
# default sampling rate : 22050

data_path = '/content/drive/MyDrive/sample'
for idx,content in data_frame.iterrows():
  # Audio analyze using Librosa  
  wave,rate= librosa.load(data_path+"/"+content[0],sr=22050)
  stft_result = librosa.stft(wave)

  # complex variable function --> real variable function
  D = np.abs(stft_result)

  # change to mel scale
  melspectrogram = librosa.feature.melspectrogram(S=D)

  plt.imshow(melspectrogram)
  plt.axis('off')
  plt.xticks([])
  plt.yticks([])
  plt.tight_layout()
  plt.subplots_adjust(left=0,bottom=0,right=1,top=1,hspace=0,wspace=0)

  # need spectrogram path 
  plt.savefig(data_path+"/spectrogram/"+content[0],bbox_inches='tight',pad_inches=0,dpi=100,format="png")

class CustomMusicDataset(Dataset):
  #transform = None / target_transform = None
  def __init__(self,labels_file,img_dir):

    # 파일 기준  
    self.img_labels = pd.read_csv(labels_file)
    self.img_dir = img_dir
    
  def __len__(self):
    return len(self.img_labels)

  def __getitem__(self,idx):
    img_path = os.path.join(self.img_dir,self.img_labels.iloc[idx,0])
    
    image = Image.open(img_path,mode="r")
    re_img = image.resize((128,128))

    r,g,b,alpha= re_img.split()

    r_resize_img = np.float32(r) / 255.0
    g_resize_img = np.float32(g) / 255.0
    b_resize_img = np.float32(b) / 255.0

    rgb_resize_img = np.asarray([r_resize_img,g_resize_img,b_resize_img])
    label = self.img_labels.iloc[idx,1]

    sample = [rgb_resize_img,label]
    return sample

class CustomConvNet(nn.Module):
    def __init__(self):
        super(CustomConvNet, self).__init__()

        self.layer1 = self.conv_module(3,16)
        self.layer2 = self.conv_module(16,32)
        self.layer3 = self.conv_module(32,64)
        self.layer4 = self.conv_module(64, 128)
        self.layer5 = self.conv_module(128,256)

        self.fc1 = nn.Linear(4096,120)
        self.fc2 = nn.Linear(120,80)
        self.fc3 = nn.Linear(80,2)
        
        self.dropout = nn.Dropout()


    def forward(self, x):
      x = self.layer1(x)
      x = self.layer2(x)
      x = self.layer3(x)
      x = self.layer4(x)
      x = self.layer5(x)
      x = x.view(-1, 4096)
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      x = self.fc3(x)

      return x

    def conv_module(self,in_num,out_num):
      return nn.Sequential(
          nn.Conv2d(in_num,out_num,kernel_size = 3, stride=1,padding = 1),
          nn.BatchNorm2d(out_num),
          nn.ReLU(),
          nn.MaxPool2d(kernel_size = 2, stride = 2)
      )


net = CustomConvNet().cuda()

# path 설정
Labels ="/content/drive/MyDrive/sample/Labels.csv"
root = "/content/drive/MyDrive/sample/spectrogram"



trainset = CustomMusicDataset(Labels,root)
trainloader = torch.utils.data.DataLoader(trainset,batch_size=10,shuffle=True)

def training():

  cuda = torch.device('cuda')
  criterion = nn.CrossEntropyLoss()
  
  if torch.cuda.is_available():
    criterion = nn.CrossEntropyLoss().cuda()
    
  optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)

  for epoch in range(20):
      running_loss = 0.0

      for i, data in enumerate(trainloader, 0):
          # get the inputs
          inputs, labels = data

          if torch.cuda.is_available():
            inputs = inputs.cuda()
            labels = labels.cuda()

          # zero the parameter gradients
          optimizer.zero_grad()

          # forward + backward + optimize
          outputs = net(inputs)
          loss = criterion(outputs, labels)

          loss.backward()
          optimizer.step()

          # print statistics
          running_loss += loss.item()

          if i%10 == 9:

            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))

            running_loss = 0.0

  print('Finished Training')

# Model Save
PATH = '/content/drive/MyDrive/net.pth'
torch.save(net.state_dict(),PATH)

def new_music_analyze(path,file_name):
  '''
  path = /content/drive/MyDrive/testMusic/Cardi B - Up [Official Music Video].wav
  file_name = Cardi B - Up [Official Music Video].wav
  folder_path =  /content/drive/MyDrive/testMusic/Cardi B - Up [Official Music Video].wav_sample
  csv_path =  /content/drive/MyDrive/testMusic/Cardi B - Up [Official Music Video].wav_sample/test_label.csv
  '''


  folder_path = path+"_sample"
  folder_path = re.sub(","," ",folder_path)
  file_name = re.sub(","," ",file_name)
  csv_path = folder_path+"/test_label.csv"

  try:
    os.mkdir(folder_path)
    data,rate = librosa.load(path)

    f = open(csv_path,"w")
    f.write("Name,Label\n")

    seconds = len(data)//22050
    five_sec_chunck = seconds // 5


    for i in range(five_sec_chunck-1):
      wave = data[rate*5*i:rate*5*(i+1)]
      stft_result = librosa.stft(wave)
      D = np.abs(stft_result)
      melspectrogram = librosa.feature.melspectrogram(S=D)

      plt.imshow(melspectrogram)
      plt.axis('off')
      plt.xticks([])
      plt.yticks([])
      plt.tight_layout()
      plt.subplots_adjust(left=0,bottom=0,right=1,top=1,hspace=0,wspace=0)

      plt.savefig(folder_path+"/"+file_name+"_"+str(i),pad_inches=0,dpi=100,format="png",bbox_inches="tight")
      f.write("%s\n"%(file_name+"_"+str(i)))

    f.close()
  except:
      print("난 이미 있어!")
      test_label = csv_path
      test_root = folder_path
      print(test_label,test_root)

      return (test_label,test_root)
  
  test_label = csv_path
  test_root = folder_path
  print(test_label,test_root)

  return (test_label,test_root)

import unicodedata

LF = open("/content/drive/MyDrive/Fun.csv","w",encoding='utf-8-sig')
RF = open("/content/drive/MyDrive/Sad.csv",'w',encoding='utf-8-sig')
LF.write("Name\n")
RF.write("Name\n")

classes = ("차분한 노래","신나는 노래")


try:
  for item in zip(content_list,test_music):
    path,file_name = item
    test_label,test_root = new_music_analyze(path,file_name)

    testset = CustomMusicDataset(test_label,test_root)
    testloader = torch.utils.data.DataLoader(testset,batch_size=1,shuffle=True)

    dataiter = iter(testloader)
    counter = {0:0,1:0}
    for idx,i in enumerate(dataiter,0):
      images,labels = i
      images = images.cuda()
      labels = labels.cuda()
      outputs=net(images)

      _,predicted = torch.max(outputs,1)

      if predicted[0] == 0:
        counter[0] += 1
      elif predicted[0] == 1:
        counter[1] += 1


    max_list = list(counter.items())
    max_list.sort(key=lambda x:x[1])

    print(file_name+"은"+classes[max_list[-1][0]])
    file_name = re.sub(","," ",file_name)
    file_name = unicodedata.normalize('NFD',file_name)
    file_name = unicodedata.normalize('NFC',file_name)

    if max_list[-1][0] == 0:
      RF.write("%s\n"%file_name)
    elif max_list[-1][0] ==1 :
      LF.write("%s\n"%file_name)

except:
  print("error")

finally:
  LF.close()
  RF.close()